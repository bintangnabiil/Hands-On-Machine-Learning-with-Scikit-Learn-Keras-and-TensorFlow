{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPl7EV/hUxzO+8TxTNv4QIk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bintangnabiil/Hands-On-Machine-Learning-with-Scikit-Learn-Keras-and-TensorFlow/blob/main/Rangkuman_Chapter_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chapter 12: Custom Models and Training with TensorFlow\n",
        "Chapter ini membahas cara membuat model kustom dan proses training menggunakan TensorFlow tingkat rendah. Kita akan mempelajari cara kerja internal TensorFlow, membuat custom layers, custom training loops, dan menggunakan TensorFlow's automatic differentiation untuk optimasi yang lebih fleksibel.\n",
        "\n",
        "##1.TensorFlow's Lower-Level API\n",
        "TensorFlow menyediakan API tingkat rendah yang memberikan kontrol penuh atas proses training dan model architecture. Berbeda dengan Keras yang high-level, API ini memungkinkan kustomisasi yang sangat detail.\n",
        "\n",
        "###Keuntungan menggunakan Lower-Level API:\n",
        "\n",
        "- Kontrol penuh atas forward pass dan backward pass\n",
        "- Kemampuan untuk mengimplementasikan algoritma training kustom\n",
        "- Debugging yang lebih mendalam\n",
        "- Optimasi performa untuk kasus khusus\n",
        "\n",
        "##2. Tensors dan Operations\n",
        "Tensor adalah struktur data dasar di TensorFlow, mirip dengan NumPy arrays tetapi dapat dijalankan di GPU dan mendukung automatic differentiation.\n",
        "\n",
        "###Karakteristik Tensor:\n",
        "\n",
        "- Immutable (tidak dapat diubah setelah dibuat)\n",
        "- Memiliki dtype (tipe data) dan shape\n",
        "- Dapat dibuat dari konstanta, variabel, atau operasi lain\n",
        "\n",
        "##3. Variables dan Constants\n",
        "Variables digunakan untuk menyimpan state yang dapat berubah (seperti weights), sedangkan Constants untuk nilai yang tetap.\n",
        "\n",
        "###Perbedaan utama:\n",
        "\n",
        "- Variables: Mutable, dapat diubah dengan .assign()\n",
        "- Constants: Immutable, nilainya tetap\n",
        "\n",
        "##4. Custom Layers\n",
        "Membuat layer kustom memungkinkan implementasi operasi yang tidak tersedia di Keras standard library.\n",
        "\n",
        "###Cara membuat custom layer:\n",
        "\n",
        "- Inherit dari tf.keras.layers.Layer\n",
        "- Override method build() untuk inisialisasi weights\n",
        "- Override method call() untuk forward pass\n",
        "- Optionally override get_config() untuk serialization\n",
        "\n",
        "##5. Custom Models\n",
        "Selain custom layers, kita juga dapat membuat model yang sepenuhnya kustom dengan logic yang kompleks.\n",
        "\n",
        "###Pendekatan untuk custom models:\n",
        "\n",
        "- Subclassing tf.keras.Model\n",
        "- Menggunakan Functional API dengan custom layers\n",
        "- Membuat model dari scratch tanpa Keras\n",
        "\n",
        "##6. Automatic Differentiation\n",
        "TensorFlow menggunakan automatic differentiation (AutoDiff) untuk menghitung gradients secara otomatis.\n",
        "\n",
        "###GradientTape:\n",
        "\n",
        "- Merekam operasi untuk forward pass\n",
        "- Menghitung gradients untuk backward pass\n",
        "- Mendukung higher-order derivatives\n",
        "\n",
        "##7. Custom Training Loops\n",
        "Training loop kustom memberikan kontrol penuh atas proses training, termasuk bagaimana loss dihitung dan bagaimana weights diupdate.\n",
        "\n",
        "###Komponen custom training loop:\n",
        "\n",
        "- Forward pass manual\n",
        "- Loss computation\n",
        "- Gradient computation dengan GradientTape\n",
        "- Weight updates dengan optimizer\n",
        "\n",
        "##8. Custom Metrics dan Losses\n",
        "Implementasi metrics dan loss functions kustom untuk kasus-kasus khusus yang tidak tersedia di TensorFlow standard library.\n",
        "\n",
        "##9. Performance Optimization\n",
        "Teknik-teknik untuk mengoptimalkan performa model kustom, termasuk penggunaan @tf.function decorator dan graph optimization."
      ],
      "metadata": {
        "id": "m_lBVw0hM_J4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementasi Kode\n",
        "##1. Dasar-dasar Tensors dan Operations"
      ],
      "metadata": {
        "id": "ruKwDCnoTEux"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzBdgTTvM5ek",
        "outputId": "8593b5c5-99c1-4022-fff3-afdacec4cce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor 1 shape: (2, 3)\n",
            "Tensor 1 dtype: <dtype: 'float32'>\n",
            "Matrix multiplication result:\n",
            "tf.Tensor(\n",
            "[[ 58.  64.]\n",
            " [139. 154.]], shape=(2, 2), dtype=float32)\n",
            "Initial weights: <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[1., 2.],\n",
            "       [3., 4.]], dtype=float32)>\n",
            "Updated weights: <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[5., 6.],\n",
            "       [7., 8.]], dtype=float32)>\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Membuat tensors\n",
        "t1 = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
        "t2 = tf.constant([[7., 8.], [9., 10.], [11., 12.]])\n",
        "\n",
        "print(\"Tensor 1 shape:\", t1.shape)\n",
        "print(\"Tensor 1 dtype:\", t1.dtype)\n",
        "\n",
        "# Operasi tensor\n",
        "result = tf.matmul(t1, t2)\n",
        "print(\"Matrix multiplication result:\")\n",
        "print(result)\n",
        "\n",
        "# Menggunakan Variables\n",
        "w = tf.Variable([[1.0, 2.0], [3.0, 4.0]])\n",
        "print(\"Initial weights:\", w)\n",
        "\n",
        "# Mengubah nilai variable\n",
        "w.assign([[5.0, 6.0], [7.0, 8.0]])\n",
        "print(\"Updated weights:\", w)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Custom Layer Implementation"
      ],
      "metadata": {
        "id": "6GXZdgemTNjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDenseLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, activation=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.activation = tf.keras.activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Inisialisasi weights\n",
        "        self.kernel = self.add_weight(\n",
        "            name='kernel',\n",
        "            shape=(input_shape[-1], self.units),\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=True\n",
        "        )\n",
        "        self.bias = self.add_weight(\n",
        "            name='bias',\n",
        "            shape=(self.units,),\n",
        "            initializer='zeros',\n",
        "            trainable=True\n",
        "        )\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Forward pass\n",
        "        output = tf.matmul(inputs, self.kernel) + self.bias\n",
        "        if self.activation:\n",
        "            output = self.activation(output)\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            'units': self.units,\n",
        "            'activation': tf.keras.activations.serialize(self.activation)\n",
        "        })\n",
        "        return config\n",
        "\n",
        "# Menggunakan custom layer\n",
        "model = tf.keras.Sequential([\n",
        "    CustomDenseLayer(64, activation='relu'),\n",
        "    CustomDenseLayer(32, activation='relu'),\n",
        "    CustomDenseLayer(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "diUILWuVTRVz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Custom Model dengan Subclassing"
      ],
      "metadata": {
        "id": "AHHqH7ikTPMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(tf.keras.Model):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Define layers\n",
        "        self.dense1 = tf.keras.layers.Dense(64, activation='relu')\n",
        "        self.dropout1 = tf.keras.layers.Dropout(0.2)\n",
        "        self.dense2 = tf.keras.layers.Dense(32, activation='relu')\n",
        "        self.dropout2 = tf.keras.layers.Dropout(0.2)\n",
        "        self.classifier = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        # Forward pass dengan logic kustom\n",
        "        x = self.dense1(inputs)\n",
        "        x = self.dropout1(x, training=training)\n",
        "        x = self.dense2(x)\n",
        "        x = self.dropout2(x, training=training)\n",
        "\n",
        "        # Tambahkan skip connection sederhana\n",
        "        if inputs.shape[-1] == x.shape[-1]:\n",
        "            x = x + inputs\n",
        "\n",
        "        return self.classifier(x)\n",
        "\n",
        "# Inisialisasi model\n",
        "custom_model = CustomModel(num_classes=10)\n",
        "\n",
        "# Build model dengan contoh input\n",
        "dummy_input = tf.random.normal((1, 784))  # Contoh untuk MNIST\n",
        "_ = custom_model(dummy_input)\n",
        "\n",
        "print(\"Model summary:\")\n",
        "custom_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "j86dzfEmTSBk",
        "outputId": "4fc3d29e-5b0f-49e0-f888-66eb3a8ec304"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"custom_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"custom_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │        \u001b[38;5;34m50,240\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)                │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m10\u001b[0m)                │           \u001b[38;5;34m330\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,240</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m52,650\u001b[0m (205.66 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,650</span> (205.66 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m52,650\u001b[0m (205.66 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,650</span> (205.66 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Automatic Differentiation dengan GradientTape"
      ],
      "metadata": {
        "id": "QMaUo5Z-TSfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh sederhana automatic differentiation\n",
        "def simple_function(x):\n",
        "    return x**2 + 2*x + 1\n",
        "\n",
        "x = tf.Variable(3.0)\n",
        "\n",
        "# Menghitung gradient\n",
        "with tf.GradientTape() as tape:\n",
        "    y = simple_function(x)\n",
        "\n",
        "dy_dx = tape.gradient(y, x)\n",
        "print(f\"f(x) = x^2 + 2x + 1\")\n",
        "print(f\"f'(x) at x=3: {dy_dx}\")\n",
        "\n",
        "# Contoh dengan neural network\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "x_train = tf.random.normal((100, 5))\n",
        "y_train = tf.random.normal((100, 1))\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    predictions = model(x_train)\n",
        "    loss = tf.keras.losses.mse(y_train, predictions)\n",
        "\n",
        "# Menghitung gradients\n",
        "gradients = tape.gradient(loss, model.trainable_variables)\n",
        "print(\"Gradients computed for\", len(gradients), \"variables\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWChnhbeTUsb",
        "outputId": "b87cfe68-adc1-4406-beb3-c2602e2f74c3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f(x) = x^2 + 2x + 1\n",
            "f'(x) at x=3: 8.0\n",
            "Gradients computed for 4 variables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Custom Training Loop"
      ],
      "metadata": {
        "id": "tB-VN2jGTVNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Persiapan data (contoh dengan dataset sederhana)\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 784).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(-1, 784).astype('float32') / 255.0\n",
        "\n",
        "# Convert to tf.data.Dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.batch(32).shuffle(1000)\n",
        "\n",
        "# Model dan optimizer\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "# Custom training step\n",
        "@tf.function\n",
        "def train_step(x_batch, y_batch):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(x_batch, training=True)\n",
        "        loss = loss_fn(y_batch, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Training loop\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "    epoch_loss = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    for x_batch, y_batch in train_dataset:\n",
        "        loss = train_step(x_batch, y_batch)\n",
        "        epoch_loss += loss\n",
        "        num_batches += 1\n",
        "\n",
        "    avg_loss = epoch_loss / num_batches\n",
        "    print(f\"Average loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-pYcG0ITZA4",
        "outputId": "b1db69c0-771d-47d3-9980-c78203084fc5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Epoch 1/3\n",
            "Average loss: 0.3001\n",
            "Epoch 2/3\n",
            "Average loss: 0.1450\n",
            "Epoch 3/3\n",
            "Average loss: 0.1089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. Custom Loss Function"
      ],
      "metadata": {
        "id": "6je3GLRNTYku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, alpha=1.0, name='custom_loss'):\n",
        "        super().__init__(name=name)\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        # Custom loss yang menggabungkan MSE dan MAE\n",
        "        mse = tf.keras.losses.mse(y_true, y_pred)\n",
        "        mae = tf.keras.losses.mae(y_true, y_pred)\n",
        "        return self.alpha * mse + (1 - self.alpha) * mae\n",
        "\n",
        "# Menggunakan custom loss\n",
        "custom_loss = CustomLoss(alpha=0.7)\n",
        "\n",
        "# Contoh penggunaan\n",
        "y_true = tf.constant([[1.0], [2.0], [3.0]])\n",
        "y_pred = tf.constant([[1.1], [1.9], [3.2]])\n",
        "\n",
        "loss_value = custom_loss(y_true, y_pred)\n",
        "print(f\"Custom loss value: {loss_value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrlPOKVfTboM",
        "outputId": "5ba69f54-6fa3-476c-c198-7e4898c18f6d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom loss value: 0.054000020027160645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7. Custom Metric"
      ],
      "metadata": {
        "id": "QzHaNJfOTb04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomAccuracy(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='custom_accuracy', **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.total = self.add_weight(name='total', initializer='zeros')\n",
        "        self.count = self.add_weight(name='count', initializer='zeros')\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        # Custom accuracy yang mempertimbangkan toleransi\n",
        "        tolerance = 0.1\n",
        "        matches = tf.abs(y_true - y_pred) <= tolerance\n",
        "        matches = tf.cast(matches, self.dtype)\n",
        "\n",
        "        if sample_weight is not None:\n",
        "            sample_weight = tf.cast(sample_weight, self.dtype)\n",
        "            matches = tf.multiply(matches, sample_weight)\n",
        "\n",
        "        self.total.assign_add(tf.reduce_sum(matches))\n",
        "        self.count.assign_add(tf.cast(tf.size(y_true), self.dtype))\n",
        "\n",
        "    def result(self):\n",
        "        return self.total / self.count\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.total.assign(0)\n",
        "        self.count.assign(0)\n",
        "\n",
        "# Menggunakan custom metric\n",
        "custom_metric = CustomAccuracy()\n",
        "\n",
        "# Contoh penggunaan\n",
        "y_true = tf.constant([1.0, 2.0, 3.0, 4.0])\n",
        "y_pred = tf.constant([1.05, 1.95, 3.08, 4.12])\n",
        "\n",
        "custom_metric.update_state(y_true, y_pred)\n",
        "print(f\"Custom accuracy: {custom_metric.result()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcSuswo8TeHF",
        "outputId": "5f4f2275-7c91-4715-a75e-95bcb4c54192"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom accuracy: 0.75\n"
          ]
        }
      ]
    }
  ]
}