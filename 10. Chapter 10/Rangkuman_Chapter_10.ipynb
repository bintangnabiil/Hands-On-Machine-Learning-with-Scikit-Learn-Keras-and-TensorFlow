{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPT3HYTaXq/zwGodorSQ1B9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bintangnabiil/Hands-On-Machine-Learning-with-Scikit-Learn-Keras-and-TensorFlow/blob/main/Rangkuman_Chapter_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chapter 10: Introduction to Artificial Neural Networks with Keras\n",
        "Chapter ini memperkenalkan konsep dasar Artificial Neural Networks (ANN) dan penggunaannya dengan Keras. Neural networks merupakan fondasi dari deep learning yang terinspirasi dari cara kerja otak manusia dalam memproses informasi.\n",
        "\n",
        "##1. From Biological to Artificial Neurons\n",
        "###Biological Neurons\n",
        "\n",
        "- Neuron biologis menerima sinyal dari neuron lain melalui dendrites\n",
        "- Sinyal diproses di cell body dan diteruskan melalui axon\n",
        "- Komunikasi antar neuron terjadi melalui synapses\n",
        "- Inspirasi untuk artificial neural networks\n",
        "\n",
        "###The Perceptron\n",
        "Perceptron adalah model neuron buatan paling sederhana:\n",
        "\n",
        "- Input: Menerima beberapa input numerical (x₁, x₂, ..., xₙ)\n",
        "- Weights: Setiap input memiliki weight (w₁, w₂, ..., wₙ)\n",
        "- Bias: Nilai tambahan untuk menggeser threshold\n",
        "- Activation Function: Fungsi yang menentukan output berdasarkan weighted sum\n",
        "\n",
        "###Formula Perceptron:\n",
        "z = w₁x₁ + w₂x₂ + ... + wₙxₙ + b\n",
        "\n",
        "output = step_function(z)\n",
        "\n",
        "###Multi-Layer Perceptron (MLP)\n",
        "\n",
        "- Terdiri dari multiple layers: input layer, hidden layers, dan output layer\n",
        "- Setiap layer terdiri dari multiple neurons\n",
        "- Feedforward: Informasi mengalir dari input ke output\n",
        "- Fully Connected: Setiap neuron terhubung ke semua neuron di layer sebelumnya\n",
        "\n",
        "##2. Training an MLP with Backpropagation\n",
        "###Forward Pass\n",
        "\n",
        "- Data input diproses layer by layer dari input ke output\n",
        "- Setiap neuron menghitung weighted sum dan menerapkan activation function\n",
        "- Output final dibandingkan dengan target untuk menghitung error\n",
        "\n",
        "###Backward Pass (Backpropagation)\n",
        "\n",
        "- Error dipropagasi mundur dari output ke input\n",
        "- Gradients dihitung untuk setiap weight dan bias\n",
        "- Weights diupdate menggunakan gradient descent\n",
        "- Chain Rule digunakan untuk menghitung gradients\n",
        "\n",
        "###Gradient Descent Variants\n",
        "\n",
        "- Batch Gradient Descent: Menggunakan seluruh training set\n",
        "- Stochastic Gradient Descent (SGD): Menggunakan satu sample per update\n",
        "- Mini-batch Gradient Descent: Menggunakan subset kecil dari training set\n",
        "\n",
        "##3. Regression MLPs\n",
        "###Characteristics\n",
        "\n",
        "- Output layer: Satu neuron tanpa activation function (atau linear activation)\n",
        "- Loss function: Mean Squared Error (MSE) atau Mean Absolute Error (MAE)\n",
        "- Cocok untuk memprediksi nilai continuous\n",
        "\n",
        "###Architecture Design\n",
        "\n",
        "- Hidden layers: 1-3 hidden layers biasanya cukup\n",
        "- Neurons per layer: Mulai dengan 10-100 neurons\n",
        "- Activation functions: ReLU untuk hidden layers\n",
        "\n",
        "##4. Classification MLPs\n",
        "###Binary Classification\n",
        "\n",
        "- Output layer: Satu neuron dengan sigmoid activation\n",
        "- Loss function: Binary crossentropy\n",
        "- Output: Probabilitas antara 0 dan 1\n",
        "\n",
        "###Multiclass Classification\n",
        "\n",
        "- Output layer: Satu neuron per class dengan softmax activation\n",
        "- Loss function: Categorical crossentropy\n",
        "- Output: Probability distribution over classes\n",
        "\n",
        "###Multilabel Classification\n",
        "\n",
        "- Output layer: Satu neuron per label dengan sigmoid activation\n",
        "- Loss function: Binary crossentropy\n",
        "- Setiap output independent\n",
        "\n",
        "##5. Implementing MLPs with Keras\n",
        "###Keras Overview\n",
        "\n",
        "- High-level API untuk building neural networks\n",
        "- Backend: TensorFlow (default), Theano, atau CNTK\n",
        "- Sequential API: Linear stack of layers\n",
        "- Functional API: Lebih fleksibel untuk complex architectures\n",
        "\n",
        "###Key Components\n",
        "\n",
        "- Model: Container untuk layers\n",
        "- Layers: Building blocks (Dense, Conv2D, LSTM, etc.)\n",
        "- Optimizers: Algorithms untuk training (Adam, SGD, RMSprop)\n",
        "- Loss Functions: Measure of prediction error\n",
        "- Metrics: Monitor training progress\n",
        "\n",
        "##6. Fine-Tuning Neural Network Hyperparameters\n",
        "###Important Hyperparameters\n",
        "\n",
        "- Number of hidden layers: Start with 1-2, increase if underfitting\n",
        "- Number of neurons per layer: Gradually decrease from input to output\n",
        "- Learning rate: Critical parameter, use adaptive optimizers\n",
        "- Batch size: Trade-off between speed and stability\n",
        "- Activation functions: ReLU family for hidden layers\n",
        "\n",
        "###Hyperparameter Tuning Strategies\n",
        "\n",
        "- Grid Search: Systematic search over parameter grid\n",
        "- Random Search: Random sampling of hyperparameters\n",
        "- Bayesian Optimization: More sophisticated approach\n",
        "- Early Stopping: Prevent overfitting"
      ],
      "metadata": {
        "id": "Crcr0ULBQBsW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementasi Kode\n",
        "##1. Basic MLP untuk Regression"
      ],
      "metadata": {
        "id": "kdj5NPZ_Q9vM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNWqmyp9P3Ce",
        "outputId": "3be6b614-a452-41ac-8f2a-947b5da10419"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 1.3857 - mae: 0.8375 - val_loss: 3.1948 - val_mae: 0.5664\n",
            "Epoch 2/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - loss: 0.5119 - mae: 0.5165 - val_loss: 0.4018 - val_mae: 0.4537\n",
            "Epoch 3/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.4313 - mae: 0.4725 - val_loss: 3.1457 - val_mae: 0.4733\n",
            "Epoch 4/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.5329 - mae: 0.4817 - val_loss: 7.7748 - val_mae: 0.5047\n",
            "Epoch 5/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.4286 - mae: 0.4497 - val_loss: 0.5359 - val_mae: 0.4617\n",
            "Epoch 6/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.3786 - mae: 0.4356 - val_loss: 0.3745 - val_mae: 0.4391\n",
            "Epoch 7/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3844 - mae: 0.4405 - val_loss: 0.3780 - val_mae: 0.4188\n",
            "Epoch 8/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3641 - mae: 0.4290 - val_loss: 0.4105 - val_mae: 0.4278\n",
            "Epoch 9/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3680 - mae: 0.4306 - val_loss: 0.4047 - val_mae: 0.4106\n",
            "Epoch 10/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3684 - mae: 0.4268 - val_loss: 0.4093 - val_mae: 0.4183\n",
            "Epoch 11/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3508 - mae: 0.4217 - val_loss: 0.3615 - val_mae: 0.4087\n",
            "Epoch 12/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3654 - mae: 0.4221 - val_loss: 0.3608 - val_mae: 0.4066\n",
            "Epoch 13/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3440 - mae: 0.4115 - val_loss: 0.3521 - val_mae: 0.4196\n",
            "Epoch 14/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3538 - mae: 0.4166 - val_loss: 0.3519 - val_mae: 0.4214\n",
            "Epoch 15/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.3364 - mae: 0.4083 - val_loss: 0.3392 - val_mae: 0.3945\n",
            "Epoch 16/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3289 - mae: 0.4041 - val_loss: 0.3148 - val_mae: 0.3945\n",
            "Epoch 17/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3298 - mae: 0.4029 - val_loss: 0.3269 - val_mae: 0.4042\n",
            "Epoch 18/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3180 - mae: 0.3974 - val_loss: 0.3326 - val_mae: 0.4036\n",
            "Epoch 19/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3402 - mae: 0.4067 - val_loss: 0.3281 - val_mae: 0.3959\n",
            "Epoch 20/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3103 - mae: 0.3940 - val_loss: 0.3269 - val_mae: 0.3894\n",
            "Epoch 21/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3135 - mae: 0.3936 - val_loss: 0.3359 - val_mae: 0.3939\n",
            "Epoch 22/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3232 - mae: 0.3962 - val_loss: 0.3536 - val_mae: 0.4014\n",
            "Epoch 23/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3132 - mae: 0.3929 - val_loss: 0.3373 - val_mae: 0.4064\n",
            "Epoch 24/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3207 - mae: 0.3942 - val_loss: 0.3340 - val_mae: 0.3833\n",
            "Epoch 25/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3299 - mae: 0.3986 - val_loss: 0.3342 - val_mae: 0.3872\n",
            "Epoch 26/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.3104 - mae: 0.3917 - val_loss: 0.3042 - val_mae: 0.3847\n",
            "Epoch 27/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3089 - mae: 0.3889 - val_loss: 0.3269 - val_mae: 0.3910\n",
            "Epoch 28/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3101 - mae: 0.3869 - val_loss: 0.3842 - val_mae: 0.3845\n",
            "Epoch 29/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3178 - mae: 0.3931 - val_loss: 0.3238 - val_mae: 0.3876\n",
            "Epoch 30/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3077 - mae: 0.3860 - val_loss: 0.3540 - val_mae: 0.4100\n",
            "Epoch 31/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3018 - mae: 0.3831 - val_loss: 0.3371 - val_mae: 0.3852\n",
            "Epoch 32/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3107 - mae: 0.3876 - val_loss: 0.3272 - val_mae: 0.3722\n",
            "Epoch 33/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3051 - mae: 0.3843 - val_loss: 0.3257 - val_mae: 0.3735\n",
            "Epoch 34/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.3101 - mae: 0.3860 - val_loss: 0.4249 - val_mae: 0.3847\n",
            "Epoch 35/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2952 - mae: 0.3780 - val_loss: 0.3391 - val_mae: 0.3829\n",
            "Epoch 36/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3013 - mae: 0.3801 - val_loss: 0.3336 - val_mae: 0.3886\n",
            "Epoch 37/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3062 - mae: 0.3855 - val_loss: 0.3251 - val_mae: 0.3816\n",
            "Epoch 38/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2944 - mae: 0.3784 - val_loss: 0.3163 - val_mae: 0.3719\n",
            "Epoch 39/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2984 - mae: 0.3788 - val_loss: 0.3383 - val_mae: 0.3737\n",
            "Epoch 40/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2982 - mae: 0.3787 - val_loss: 0.3017 - val_mae: 0.3754\n",
            "Epoch 41/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3015 - mae: 0.3802 - val_loss: 0.3234 - val_mae: 0.3821\n",
            "Epoch 42/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3084 - mae: 0.3814 - val_loss: 0.3322 - val_mae: 0.3700\n",
            "Epoch 43/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2977 - mae: 0.3774 - val_loss: 0.2880 - val_mae: 0.3679\n",
            "Epoch 44/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.2887 - mae: 0.3732 - val_loss: 0.3054 - val_mae: 0.3664\n",
            "Epoch 45/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2986 - mae: 0.3763 - val_loss: 0.3217 - val_mae: 0.3745\n",
            "Epoch 46/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2881 - mae: 0.3714 - val_loss: 0.3328 - val_mae: 0.3665\n",
            "Epoch 47/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2832 - mae: 0.3699 - val_loss: 0.3146 - val_mae: 0.3688\n",
            "Epoch 48/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2863 - mae: 0.3694 - val_loss: 0.3151 - val_mae: 0.3646\n",
            "Epoch 49/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2794 - mae: 0.3640 - val_loss: 0.3057 - val_mae: 0.3894\n",
            "Epoch 50/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2921 - mae: 0.3757 - val_loss: 0.3113 - val_mae: 0.3664\n",
            "Epoch 51/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2813 - mae: 0.3663 - val_loss: 0.3487 - val_mae: 0.3959\n",
            "Epoch 52/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2885 - mae: 0.3715 - val_loss: 0.3356 - val_mae: 0.3815\n",
            "Epoch 53/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2876 - mae: 0.3720 - val_loss: 0.2983 - val_mae: 0.3721\n",
            "Epoch 54/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2851 - mae: 0.3702 - val_loss: 0.3513 - val_mae: 0.3890\n",
            "Epoch 55/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2812 - mae: 0.3657 - val_loss: 0.3395 - val_mae: 0.3951\n",
            "Epoch 56/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2796 - mae: 0.3686 - val_loss: 0.2964 - val_mae: 0.3653\n",
            "Epoch 57/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2796 - mae: 0.3656 - val_loss: 0.3102 - val_mae: 0.3621\n",
            "Epoch 58/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2764 - mae: 0.3662 - val_loss: 0.3092 - val_mae: 0.3768\n",
            "Epoch 59/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2810 - mae: 0.3672 - val_loss: 0.3291 - val_mae: 0.3616\n",
            "Epoch 60/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2854 - mae: 0.3682 - val_loss: 0.2933 - val_mae: 0.3676\n",
            "Epoch 61/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2779 - mae: 0.3629 - val_loss: 0.3286 - val_mae: 0.3728\n",
            "Epoch 62/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2783 - mae: 0.3624 - val_loss: 0.3112 - val_mae: 0.3615\n",
            "Epoch 63/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2665 - mae: 0.3556 - val_loss: 0.3587 - val_mae: 0.3795\n",
            "Epoch 64/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2871 - mae: 0.3687 - val_loss: 0.2924 - val_mae: 0.3671\n",
            "Epoch 65/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2702 - mae: 0.3590 - val_loss: 0.3297 - val_mae: 0.3690\n",
            "Epoch 66/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2774 - mae: 0.3632 - val_loss: 0.2777 - val_mae: 0.3644\n",
            "Epoch 67/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2722 - mae: 0.3623 - val_loss: 0.3173 - val_mae: 0.3633\n",
            "Epoch 68/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2773 - mae: 0.3644 - val_loss: 0.3062 - val_mae: 0.3746\n",
            "Epoch 69/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2808 - mae: 0.3649 - val_loss: 0.3248 - val_mae: 0.3693\n",
            "Epoch 70/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2710 - mae: 0.3592 - val_loss: 0.3065 - val_mae: 0.3650\n",
            "Epoch 71/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2662 - mae: 0.3568 - val_loss: 0.2798 - val_mae: 0.3611\n",
            "Epoch 72/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2747 - mae: 0.3623 - val_loss: 0.2893 - val_mae: 0.3587\n",
            "Epoch 73/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2650 - mae: 0.3568 - val_loss: 0.3359 - val_mae: 0.3655\n",
            "Epoch 74/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2753 - mae: 0.3643 - val_loss: 0.2871 - val_mae: 0.3584\n",
            "Epoch 75/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2641 - mae: 0.3581 - val_loss: 0.3278 - val_mae: 0.3603\n",
            "Epoch 76/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2693 - mae: 0.3598 - val_loss: 0.3020 - val_mae: 0.3596\n",
            "Epoch 77/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2781 - mae: 0.3604 - val_loss: 0.3076 - val_mae: 0.3617\n",
            "Epoch 78/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2775 - mae: 0.3594 - val_loss: 0.3453 - val_mae: 0.3703\n",
            "Epoch 79/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2792 - mae: 0.3637 - val_loss: 0.2862 - val_mae: 0.3615\n",
            "Epoch 80/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2739 - mae: 0.3609 - val_loss: 0.2756 - val_mae: 0.3543\n",
            "Epoch 81/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2643 - mae: 0.3545 - val_loss: 0.2869 - val_mae: 0.3562\n",
            "Epoch 82/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2645 - mae: 0.3542 - val_loss: 0.3007 - val_mae: 0.3671\n",
            "Epoch 83/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2662 - mae: 0.3610 - val_loss: 0.2867 - val_mae: 0.3633\n",
            "Epoch 84/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2600 - mae: 0.3518 - val_loss: 0.3233 - val_mae: 0.3589\n",
            "Epoch 85/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2791 - mae: 0.3613 - val_loss: 0.2951 - val_mae: 0.3569\n",
            "Epoch 86/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2606 - mae: 0.3532 - val_loss: 0.2707 - val_mae: 0.3556\n",
            "Epoch 87/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2634 - mae: 0.3546 - val_loss: 0.3208 - val_mae: 0.3786\n",
            "Epoch 88/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2593 - mae: 0.3521 - val_loss: 0.2785 - val_mae: 0.3624\n",
            "Epoch 89/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2695 - mae: 0.3578 - val_loss: 0.2717 - val_mae: 0.3554\n",
            "Epoch 90/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2605 - mae: 0.3540 - val_loss: 0.3510 - val_mae: 0.3634\n",
            "Epoch 91/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2644 - mae: 0.3537 - val_loss: 0.3092 - val_mae: 0.3619\n",
            "Epoch 92/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2725 - mae: 0.3582 - val_loss: 0.2717 - val_mae: 0.3602\n",
            "Epoch 93/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2740 - mae: 0.3602 - val_loss: 0.2717 - val_mae: 0.3578\n",
            "Epoch 94/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2586 - mae: 0.3503 - val_loss: 0.3045 - val_mae: 0.3644\n",
            "Epoch 95/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2613 - mae: 0.3546 - val_loss: 0.2983 - val_mae: 0.3589\n",
            "Epoch 96/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2806 - mae: 0.3629 - val_loss: 0.2958 - val_mae: 0.3581\n",
            "Epoch 97/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2575 - mae: 0.3482 - val_loss: 0.2770 - val_mae: 0.3679\n",
            "Epoch 98/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.2560 - mae: 0.3490 - val_loss: 0.3489 - val_mae: 0.3713\n",
            "Epoch 99/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2676 - mae: 0.3551 - val_loss: 0.2871 - val_mae: 0.3609\n",
            "Epoch 100/100\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2631 - mae: 0.3505 - val_loss: 0.3857 - val_mae: 0.3760\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2795 - mae: 0.3752\n",
            "Test MAE: 0.3751074969768524\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dan prepare data\n",
        "housing = fetch_california_housing()\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    housing.data, housing.target, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_valid_scaled = scaler.transform(X_valid)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build model\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(30, activation=\"relu\"),\n",
        "    keras.layers.Dense(1)  # No activation for regression\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss=\"mse\", optimizer=\"sgd\", metrics=[\"mae\"])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100,\n",
        "                   validation_data=(X_valid_scaled, y_valid),\n",
        "                   verbose=1)\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test MAE: {test_mae}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. MLP untuk Binary Classification"
      ],
      "metadata": {
        "id": "kfCFeVxaRLxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Generate synthetic binary classification data\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2,\n",
        "                          n_redundant=0, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                   random_state=42)\n",
        "\n",
        "# Standardize\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Build binary classification model\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(64, activation=\"relu\", input_shape=[20]),\n",
        "    keras.layers.Dense(32, activation=\"relu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")  # Sigmoid for binary\n",
        "])\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "             optimizer=\"adam\",\n",
        "             metrics=[\"accuracy\"])\n",
        "\n",
        "# Train\n",
        "history = model.fit(X_train_scaled, y_train, epochs=50,\n",
        "                   validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFFVG9W_RNbo",
        "outputId": "bf889829-edba-43b5-d43f-131436b40210"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5537 - loss: 0.7103 - val_accuracy: 0.6500 - val_loss: 0.6355\n",
            "Epoch 2/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7658 - loss: 0.5705 - val_accuracy: 0.7625 - val_loss: 0.5542\n",
            "Epoch 3/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8190 - loss: 0.4935 - val_accuracy: 0.7750 - val_loss: 0.4883\n",
            "Epoch 4/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8259 - loss: 0.4390 - val_accuracy: 0.7937 - val_loss: 0.4400\n",
            "Epoch 5/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8517 - loss: 0.3914 - val_accuracy: 0.7875 - val_loss: 0.4046\n",
            "Epoch 6/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8711 - loss: 0.3590 - val_accuracy: 0.8125 - val_loss: 0.3820\n",
            "Epoch 7/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8779 - loss: 0.3515 - val_accuracy: 0.8250 - val_loss: 0.3674\n",
            "Epoch 8/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8894 - loss: 0.3110 - val_accuracy: 0.8500 - val_loss: 0.3516\n",
            "Epoch 9/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8996 - loss: 0.2821 - val_accuracy: 0.8375 - val_loss: 0.3461\n",
            "Epoch 10/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8916 - loss: 0.2966 - val_accuracy: 0.8500 - val_loss: 0.3437\n",
            "Epoch 11/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9004 - loss: 0.2654 - val_accuracy: 0.8562 - val_loss: 0.3399\n",
            "Epoch 12/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9297 - loss: 0.2277 - val_accuracy: 0.8500 - val_loss: 0.3375\n",
            "Epoch 13/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9212 - loss: 0.2400 - val_accuracy: 0.8500 - val_loss: 0.3378\n",
            "Epoch 14/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9086 - loss: 0.2383 - val_accuracy: 0.8438 - val_loss: 0.3383\n",
            "Epoch 15/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9167 - loss: 0.2254 - val_accuracy: 0.8375 - val_loss: 0.3334\n",
            "Epoch 16/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9282 - loss: 0.2160 - val_accuracy: 0.8375 - val_loss: 0.3389\n",
            "Epoch 17/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9151 - loss: 0.2438 - val_accuracy: 0.8438 - val_loss: 0.3302\n",
            "Epoch 18/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9240 - loss: 0.2296 - val_accuracy: 0.8438 - val_loss: 0.3443\n",
            "Epoch 19/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9344 - loss: 0.2055 - val_accuracy: 0.8375 - val_loss: 0.3408\n",
            "Epoch 20/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9143 - loss: 0.2304 - val_accuracy: 0.8375 - val_loss: 0.3370\n",
            "Epoch 21/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9495 - loss: 0.1711 - val_accuracy: 0.8313 - val_loss: 0.3392\n",
            "Epoch 22/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9541 - loss: 0.1872 - val_accuracy: 0.8375 - val_loss: 0.3425\n",
            "Epoch 23/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9616 - loss: 0.1532 - val_accuracy: 0.8313 - val_loss: 0.3467\n",
            "Epoch 24/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9640 - loss: 0.1569 - val_accuracy: 0.8313 - val_loss: 0.3391\n",
            "Epoch 25/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9600 - loss: 0.1550 - val_accuracy: 0.8250 - val_loss: 0.3495\n",
            "Epoch 26/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9517 - loss: 0.1627 - val_accuracy: 0.8313 - val_loss: 0.3478\n",
            "Epoch 27/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9549 - loss: 0.1469 - val_accuracy: 0.8250 - val_loss: 0.3562\n",
            "Epoch 28/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9710 - loss: 0.1310 - val_accuracy: 0.8250 - val_loss: 0.3526\n",
            "Epoch 29/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9684 - loss: 0.1325 - val_accuracy: 0.8250 - val_loss: 0.3640\n",
            "Epoch 30/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9727 - loss: 0.1127 - val_accuracy: 0.8250 - val_loss: 0.3580\n",
            "Epoch 31/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9709 - loss: 0.1345 - val_accuracy: 0.8250 - val_loss: 0.3712\n",
            "Epoch 32/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9745 - loss: 0.1315 - val_accuracy: 0.8250 - val_loss: 0.3612\n",
            "Epoch 33/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9749 - loss: 0.1134 - val_accuracy: 0.8375 - val_loss: 0.3695\n",
            "Epoch 34/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9791 - loss: 0.1154 - val_accuracy: 0.8313 - val_loss: 0.3784\n",
            "Epoch 35/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9814 - loss: 0.0910 - val_accuracy: 0.8313 - val_loss: 0.3839\n",
            "Epoch 36/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9768 - loss: 0.0946 - val_accuracy: 0.8313 - val_loss: 0.3939\n",
            "Epoch 37/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9766 - loss: 0.0933 - val_accuracy: 0.8313 - val_loss: 0.3945\n",
            "Epoch 38/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9717 - loss: 0.1075 - val_accuracy: 0.8313 - val_loss: 0.3990\n",
            "Epoch 39/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9814 - loss: 0.0851 - val_accuracy: 0.8375 - val_loss: 0.4003\n",
            "Epoch 40/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9892 - loss: 0.0738 - val_accuracy: 0.8250 - val_loss: 0.4058\n",
            "Epoch 41/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9871 - loss: 0.0796 - val_accuracy: 0.8313 - val_loss: 0.4150\n",
            "Epoch 42/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9918 - loss: 0.0610 - val_accuracy: 0.8250 - val_loss: 0.4249\n",
            "Epoch 43/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9848 - loss: 0.0719 - val_accuracy: 0.8188 - val_loss: 0.4302\n",
            "Epoch 44/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9869 - loss: 0.0670 - val_accuracy: 0.8250 - val_loss: 0.4364\n",
            "Epoch 45/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9936 - loss: 0.0601 - val_accuracy: 0.8188 - val_loss: 0.4430\n",
            "Epoch 46/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9893 - loss: 0.0659 - val_accuracy: 0.8125 - val_loss: 0.4526\n",
            "Epoch 47/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9922 - loss: 0.0556 - val_accuracy: 0.8188 - val_loss: 0.4640\n",
            "Epoch 48/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9952 - loss: 0.0500 - val_accuracy: 0.8188 - val_loss: 0.4576\n",
            "Epoch 49/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9952 - loss: 0.0526 - val_accuracy: 0.8188 - val_loss: 0.4716\n",
            "Epoch 50/50\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9923 - loss: 0.0528 - val_accuracy: 0.8125 - val_loss: 0.4825\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7899 - loss: 0.5732  \n",
            "Test Accuracy: 0.8050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. MLP untuk Multiclass Classification"
      ],
      "metadata": {
        "id": "3E5W6aYXRPrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                   random_state=42)\n",
        "\n",
        "# Standardize\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "# Build multiclass model\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(32, activation=\"relu\", input_shape=[4]),\n",
        "    keras.layers.Dense(16, activation=\"relu\"),\n",
        "    keras.layers.Dense(3, activation=\"softmax\")  # 3 classes\n",
        "])\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "             optimizer=\"adam\",\n",
        "             metrics=[\"accuracy\"])\n",
        "\n",
        "# Train\n",
        "history = model.fit(X_train_scaled, y_train_cat, epochs=100,\n",
        "                   validation_split=0.2, verbose=0)\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test_cat)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEqdsDOgRRD7",
        "outputId": "a7272080-6c0d-473d-ef3c-71eaa0191260"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.1118\n",
            "Test Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Hyperparameter Tuning dengan Keras Tuner"
      ],
      "metadata": {
        "id": "1xNWshqZRSzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q keras-tuner"
      ],
      "metadata": {
        "id": "v7Mu7SVeTV4R"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install: pip install keras-tuner\n",
        "\n",
        "import keras_tuner as kt\n",
        "import shutil\n",
        "shutil.rmtree('untitled_project', ignore_errors=True)\n",
        "\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Input(shape=(X_train_scaled.shape[1],)))\n",
        "\n",
        "    for i in range(hp.Int('num_layers', 2, 20)):\n",
        "        model.add(keras.layers.Dense(\n",
        "            units=hp.Int(f'units_{i}', min_value=32, max_value=512, step=32),\n",
        "            activation='relu'))\n",
        "\n",
        "    model.add(keras.layers.Dense(1))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=hp.Choice('optimizer', ['adam', 'rmsprop', 'sgd']),\n",
        "        loss='mse',\n",
        "        metrics=['mae'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create tuner\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=5,\n",
        "    directory='untitled_project',  # ini akan dibuat ulang\n",
        "    overwrite=True)\n",
        "\n",
        "# Search\n",
        "tuner.search(X_train_scaled, y_train, epochs=10,\n",
        "            validation_data=(X_valid_scaled, y_valid))\n",
        "\n",
        "# Get best model\n",
        "best_model = tuner.get_best_models()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "C2tmDIYYRTtj",
        "outputId": "517d68a2-b236-4f04-c0b2-05d5bad6430a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 Complete [00h 00m 05s]\n",
            "\n",
            "Best val_loss So Far: None\n",
            "Total elapsed time: 00h 00m 06s\n",
            "\n",
            "Search: Running Trial #3\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "18                |12                |num_layers\n",
            "64                |64                |units_0\n",
            "384               |416               |units_1\n",
            "adam              |sgd               |optimizer\n",
            "192               |32                |units_2\n",
            "64                |32                |units_3\n",
            "96                |32                |units_4\n",
            "96                |32                |units_5\n",
            "192               |32                |units_6\n",
            "256               |32                |units_7\n",
            "352               |32                |units_8\n",
            "448               |32                |units_9\n",
            "32                |32                |units_10\n",
            "512               |32                |units_11\n",
            "\n",
            "Epoch 1/10\n",
            "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 7s/step - loss: 1.9999 - mae: 1.1250"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n",
            "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n",
            "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n",
            "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n",
            "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n",
            "    return model.fit(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/input_spec.py\", line 227, in assert_input_compatibility\n",
            "    raise ValueError(\n",
            "ValueError: Exception encountered when calling Sequential.call().\n",
            "\n",
            "\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 4, but received input with shape (None, 8)\u001b[0m\n",
            "\n",
            "Arguments received by Sequential.call():\n",
            "  • inputs=tf.Tensor(shape=(None, 8), dtype=float32)\n",
            "  • training=False\n",
            "  • mask=None\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 4, but received input with shape (None, 8)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 8), dtype=float32)\n  • training=False\n  • mask=None\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-068ece7804fe>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m tuner.search(X_train_scaled, y_train, epochs=10, \n\u001b[0m\u001b[1;32m     35\u001b[0m             validation_data=(X_valid_scaled, y_valid))\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36mon_trial_end\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTrial\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/oracle.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mLOCKS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mTHREADS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthread_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mneed_acquire\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mTHREADS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/oracle.py\u001b[0m in \u001b[0;36mend_trial\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_order\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_consecutive_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/oracle.py\u001b[0m in \u001b[0;36m_check_consecutive_failures\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    543\u001b[0m                 \u001b[0mconsecutive_failures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconsecutive_failures\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_consecutive_failed_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m                 raise RuntimeError(\n\u001b[0m\u001b[1;32m    546\u001b[0m                     \u001b[0;34m\"Number of consecutive failures exceeded the limit \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m                     \u001b[0;34mf\"of {self.max_consecutive_failed_trials}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/layers/input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 4, but received input with shape (None, 8)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 8), dtype=float32)\n  • training=False\n  • mask=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Visualisasi Training History"
      ],
      "metadata": {
        "id": "_rrFdseERWmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curves(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Plot training & validation loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot training & validation accuracy (if available)\n",
        "    if 'accuracy' in history.history:\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "        plt.title('Model Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "1VHGwrILRYL4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. Early Stopping dan Model Checkpointing"
      ],
      "metadata": {
        "id": "lTjen2WVRade"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define callbacks\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "    'best_model.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7)\n",
        "\n",
        "# Train with callbacks\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    epochs=200,\n",
        "    validation_data=(X_valid_scaled, y_valid),\n",
        "    callbacks=[early_stopping, model_checkpoint, reduce_lr],\n",
        "    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "BSa2zLewRbgA",
        "outputId": "35fb0a71-ff72-419f-d2e6-54f638fba8f6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None,), output.shape=(None, 3)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-d2f1cbb2ff28>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Train with callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/nn.py\u001b[0m in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m    651\u001b[0m         )\n\u001b[1;32m    652\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    654\u001b[0m             \u001b[0;34m\"Arguments `target` and `output` must have the same rank \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;34m\"(ndim). Received: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None,), output.shape=(None, 3)"
          ]
        }
      ]
    }
  ]
}